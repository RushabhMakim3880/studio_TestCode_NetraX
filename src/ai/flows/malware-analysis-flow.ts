'use server';
/**
 * @fileOverview An AI flow for simulating malware analysis.
 *
 * - analyzeFile - Generates a simulated analysis report for a file.
 * - MalwareAnalysisInput - The input type for the analyzeFile function.
 * - MalwareAnalysisOutput - The return type for the analyzeFile function.
 */

import {ai} from '@/ai/genkit';
import {z} from 'genkit';

const MalwareAnalysisInputSchema = z.object({
  filename: z.string().describe('The name of the file to analyze.'),
  fileSize: z.number().describe('The size of the file in bytes.'),
});
export type MalwareAnalysisInput = z.infer<typeof MalwareAnalysisInputSchema>;

const PeSectionSchema = z.object({
  name: z.string().describe('The name of the PE section (e.g., .text, .data).'),
  virtualAddress: z.string().describe('The virtual address of the section.'),
  virtualSize: z.string().describe('The virtual size of the section.'),
  entropy: z.number().min(0).max(8).describe('The calculated entropy of the section.'),
});

const MalwareAnalysisOutputSchema = z.object({
  verdict: z.string().describe('A high-level verdict on the file (e.g., Malicious, Suspicious, Safe).'),
  threatName: z.string().optional().describe('The name of the detected threat, if any (e.g., Trojan.Generic.KD.3142, Ransomware.WannaCry).'),
  fileInfo: z.object({
    md5: z.string().length(32).describe('The simulated MD5 hash of the file.'),
    sha1: z.string().length(40).describe('The simulated SHA1 hash of the file.'),
    sha256: z.string().length(64).describe('The simulated SHA256 hash of the file.'),
    fileType: z.string().describe('The identified file type (e.g., "PE32 executable (GUI) Intel 80386, for MS Windows").'),
  }),
  peInfo: z.object({
    entryPoint: z.string().describe('The entry point address of the PE file.'),
    imageBase: z.string().describe('The image base address.'),
    sections: z.array(PeSectionSchema).describe('A list of PE sections.'),
  }).optional().describe('Information specific to PE files. Omit if the file is not a PE file.'),
  detectedStrings: z.array(z.string()).describe('A list of 5-10 interesting or suspicious strings found in the file.'),
  analysisSummary: z.string().describe('A 2-3 sentence summary of the analysis findings and key indicators of compromise.'),
});
export type MalwareAnalysisOutput = z.infer<typeof MalwareAnalysisOutputSchema>;

export async function analyzeFile(input: MalwareAnalysisInput): Promise<MalwareAnalysisOutput> {
  return malwareAnalysisFlow(input);
}

const prompt = ai.definePrompt({
  name: 'malwareAnalysisPrompt',
  input: {schema: MalwareAnalysisInputSchema},
  output: {schema: MalwareAnalysisOutputSchema},
  prompt: `You are a static malware analysis sandbox.
  Your task is to generate a realistic-looking, simulated analysis report for a given file.

  File Name: {{{filename}}}
  File Size: {{{fileSize}}} bytes

  Based on the filename, generate a plausible report.
  - If the file is an executable (.exe, .dll), generate PE Info. Otherwise, omit the peInfo field.
  - Create realistic-looking but fake hashes. The MD5 hash must be 32 hexadecimal characters. The SHA1 hash must be 40 hexadecimal characters. The SHA256 hash must be 64 hexadecimal characters.
  - Identify a plausible file type.
  - Extract a short list of interesting or suspicious-looking strings.
  - Provide a high-level verdict (Safe, Suspicious, Malicious) and a plausible threat name if malicious.
  - Write a short summary explaining the verdict based on the simulated findings (e.g., high entropy in a section, suspicious API calls suggested by strings, etc.).
  
  Do not use real malware data. The output should be purely for simulation. Do not add conversational text.
  `,
});

const malwareAnalysisFlow = ai.defineFlow(
  {
    name: 'malwareAnalysisFlow',
    inputSchema: MalwareAnalysisInputSchema,
    outputSchema: MalwareAnalysisOutputSchema,
  },
  async input => {
    const {output} = await prompt(input);
    return output!;
  }
);
